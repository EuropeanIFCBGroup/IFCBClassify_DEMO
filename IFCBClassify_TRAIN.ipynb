{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6800a4f",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "789abb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard Python libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from collections import OrderedDict\n",
    "\n",
    "#Weights and Biases - included for experiment tracking\n",
    "#import wandb\n",
    "\n",
    "#custom libraries included with project\n",
    "from utils.RunBuilder import RunBuilder\n",
    "from utils.RunManager import RunManager\n",
    "from utils.ModelFactory import ModelFactory\n",
    "from utils.DatasetFactory import DatasetFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf29690",
   "metadata": {},
   "source": [
    "SETTING PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bdf5adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Parameters\n",
    "test_dataset_split_size = 0.2\n",
    "\n",
    "#image input dimensions - different architectures expect different input sizes \n",
    "#generally ok to keep this at 224 x 224 unless using Inception (299 x 299) or AlexNet (227 x 227)\n",
    "image_input_width = 224\n",
    "image_input_height = 224\n",
    "\n",
    "#where to look for the training data\n",
    "data_training_directory = \"training_data/V1\"\n",
    "dataset_version = \"V1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c090d8",
   "metadata": {},
   "source": [
    "HYPER-PARAMETER DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79ae0de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = OrderedDict(\n",
    "    #LEARNING RATE - Number of steps adjust the model by at each epoch\n",
    "    lr = [0.001, 0.0001],\n",
    "    #BATCH SIZE - how many images to pass at once to the model\n",
    "    #WARNING: setting batch size too large may cause out of memeory issues\n",
    "    batch_size = [64],\n",
    "    #SHUFFLE - shuffle the dataset at each epoch to change order in which images are learnt\n",
    "    shuffle = [True],\n",
    "    #NUM WORKERS - how many processes to use for dataloading - can speed up learning if you have resources\n",
    "    num_workers = [0],\n",
    "    #EPOCHS - how many epochs to run the learning for\n",
    "    epochs = [5],\n",
    "    \n",
    "    trainset = ['dataset_squarepad', 'dataset_fullpad'],\n",
    "    model = ['resnet50'],\n",
    "    \n",
    "    # For a full list of possible models check out https://pytorch.org/vision/0.21/models.html\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b51d10",
   "metadata": {},
   "source": [
    "CHECK FOR GPU SUPPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d68665e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#check for GPU support \n",
    "#WARNING - need to check correct version of PyTorch is installed for GPU support\n",
    "if torch.cuda.is_available:\n",
    "   device = 'cuda'\n",
    "else:\n",
    "   device = 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e933ebb",
   "metadata": {},
   "source": [
    "DEFINE DATASET & CLASSLIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62af1f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  6\n",
      "['Asterionellopsis', 'Chaetoceros', 'Dinophysis', 'Octactis', 'Pseudo-nitzschia', 'Tripos']\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.ImageFolder(data_training_directory)\n",
    "\n",
    "#Class Information from dataset\n",
    "number_of_classes = len(dataset.classes)\n",
    "print(\"Number of classes: \" ,number_of_classes)\n",
    "class_names = dataset.classes\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d3276a",
   "metadata": {},
   "source": [
    "LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19abedfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#define active datasets\n",
    "trainsets = {\n",
    "    #image only datasets\n",
    "    'dataset' : DatasetFactory.get_dataset('dataset', data_training_directory, test_dataset_split_size,  image_input_width, image_input_height),\n",
    "    'dataset_normalised' : DatasetFactory.get_dataset('dataset_normalised', data_training_directory, test_dataset_split_size,  image_input_width, image_input_height),\n",
    "    'dataset_squarepad' : DatasetFactory.get_dataset('dataset_squarepad', data_training_directory, test_dataset_split_size,  image_input_width, image_input_height),\n",
    "    'dataset_fullpad' : DatasetFactory.get_dataset('dataset_fullpad', data_training_directory, test_dataset_split_size,  image_input_width, image_input_height),\n",
    "    'dataset_reflectpad' : DatasetFactory.get_dataset('dataset_reflectpad', data_training_directory, test_dataset_split_size,  image_input_width, image_input_height),\n",
    "    'dataset_squarepad_normalised' : DatasetFactory.get_dataset('dataset_squarepad_normalised', data_training_directory, test_dataset_split_size,  image_input_width, image_input_height),\n",
    "    'dataset_fullpad_normalised' : DatasetFactory.get_dataset('dataset_fullpad_normalised', data_training_directory, test_dataset_split_size,  image_input_width, image_input_height),\n",
    "    'dataset_reflectpad' : DatasetFactory.get_dataset('dataset_reflectpad', data_training_directory, test_dataset_split_size,  image_input_width, image_input_height),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e47dcd3",
   "metadata": {},
   "source": [
    "MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c50444e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1\n",
      "\n",
      "TRAINING\n",
      "loss: 1.791747  [   64/ 4800]\n",
      "Correct: 4572 / 4800 \n",
      "Accuracy: 95.2%, Avg loss: 0.149822 \n",
      "\n",
      "TESTING\n",
      "Correct: 1076.0 / 1200 \n",
      "Accuracy: 89.7%, Avg loss: 0.333117 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.8945530652999878\n",
      "Best Epoch F1:  0\n",
      "Saving new best model...\n",
      "\n",
      "EPOCH 2\n",
      "\n",
      "TRAINING\n",
      "loss: 0.142402  [   64/ 4800]\n",
      "Correct: 4677 / 4800 \n",
      "Accuracy: 97.4%, Avg loss: 0.080727 \n",
      "\n",
      "TESTING\n",
      "Correct: 1173.0 / 1200 \n",
      "Accuracy: 97.8%, Avg loss: 0.065745 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.9773824214935303\n",
      "Best Epoch F1:  0.8945530652999878\n",
      "Saving new best model...\n",
      "\n",
      "EPOCH 3\n",
      "\n",
      "TRAINING\n",
      "loss: 0.045774  [   64/ 4800]\n",
      "Correct: 4782 / 4800 \n",
      "Accuracy: 99.6%, Avg loss: 0.013503 \n",
      "\n",
      "TESTING\n",
      "Correct: 1186.0 / 1200 \n",
      "Accuracy: 98.8%, Avg loss: 0.045454 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.9882955551147461\n",
      "Best Epoch F1:  0.9773824214935303\n",
      "Saving new best model...\n",
      "\n",
      "EPOCH 4\n",
      "\n",
      "TRAINING\n",
      "loss: 0.000489  [   64/ 4800]\n",
      "Correct: 4736 / 4800 \n",
      "Accuracy: 98.7%, Avg loss: 0.042640 \n",
      "\n",
      "TESTING\n",
      "Correct: 194.0 / 1200 \n",
      "Accuracy: 16.2%, Avg loss: 76.534667 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.04499760642647743\n",
      "Best Epoch F1:  0.9882955551147461\n",
      "\n",
      "EPOCH 5\n",
      "\n",
      "TRAINING\n",
      "loss: 0.074779  [   64/ 4800]\n",
      "Correct: 4755 / 4800 \n",
      "Accuracy: 99.1%, Avg loss: 0.035603 \n",
      "\n",
      "TESTING\n",
      "Correct: 1165.0 / 1200 \n",
      "Accuracy: 97.1%, Avg loss: 0.123338 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.9705927968025208\n",
      "Best Epoch F1:  0.9882955551147461\n",
      "\n",
      "Best Epoch:  3  \n",
      " Best F1 Score:  0.9882955551147461\n",
      "\n",
      "EPOCH 1\n",
      "\n",
      "TRAINING\n",
      "loss: 1.815728  [   64/ 4800]\n",
      "Correct: 4524 / 4800 \n",
      "Accuracy: 94.2%, Avg loss: 0.179022 \n",
      "\n",
      "TESTING\n",
      "Correct: 1131.0 / 1200 \n",
      "Accuracy: 94.2%, Avg loss: 0.182177 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.9409517049789429\n",
      "Best Epoch F1:  0\n",
      "Saving new best model...\n",
      "\n",
      "EPOCH 2\n",
      "\n",
      "TRAINING\n",
      "loss: 0.158135  [   64/ 4800]\n",
      "Correct: 4709 / 4800 \n",
      "Accuracy: 98.1%, Avg loss: 0.066721 \n",
      "\n",
      "TESTING\n",
      "Correct: 1158.0 / 1200 \n",
      "Accuracy: 96.5%, Avg loss: 0.128078 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.9650991559028625\n",
      "Best Epoch F1:  0.9409517049789429\n",
      "Saving new best model...\n",
      "\n",
      "EPOCH 3\n",
      "\n",
      "TRAINING\n",
      "loss: 0.052901  [   64/ 4800]\n",
      "Correct: 4738 / 4800 \n",
      "Accuracy: 98.7%, Avg loss: 0.041366 \n",
      "\n",
      "TESTING\n",
      "Correct: 1193.0 / 1200 \n",
      "Accuracy: 99.4%, Avg loss: 0.031316 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.994182288646698\n",
      "Best Epoch F1:  0.9650991559028625\n",
      "Saving new best model...\n",
      "\n",
      "EPOCH 4\n",
      "\n",
      "TRAINING\n",
      "loss: 0.001945  [   64/ 4800]\n",
      "Correct: 4777 / 4800 \n",
      "Accuracy: 99.5%, Avg loss: 0.014954 \n",
      "\n",
      "TESTING\n",
      "Correct: 1184.0 / 1200 \n",
      "Accuracy: 98.7%, Avg loss: 0.053600 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.9866843819618225\n",
      "Best Epoch F1:  0.994182288646698\n",
      "\n",
      "EPOCH 5\n",
      "\n",
      "TRAINING\n",
      "loss: 0.002503  [   64/ 4800]\n",
      "Correct: 4796 / 4800 \n",
      "Accuracy: 99.9%, Avg loss: 0.002828 \n",
      "\n",
      "TESTING\n",
      "Correct: 1176.0 / 1200 \n",
      "Accuracy: 98.0%, Avg loss: 0.065337 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.9800182580947876\n",
      "Best Epoch F1:  0.994182288646698\n",
      "\n",
      "Best Epoch:  3  \n",
      " Best F1 Score:  0.994182288646698\n",
      "\n",
      "EPOCH 1\n",
      "\n",
      "TRAINING\n",
      "loss: 1.791747  [   64/ 4800]\n",
      "Correct: 4524 / 4800 \n",
      "Accuracy: 94.2%, Avg loss: 0.324320 \n",
      "\n",
      "TESTING\n",
      "Correct: 1144.0 / 1200 \n",
      "Accuracy: 95.3%, Avg loss: 0.124984 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.9535766839981079\n",
      "Best Epoch F1:  0\n",
      "Saving new best model...\n",
      "\n",
      "EPOCH 2\n",
      "\n",
      "TRAINING\n",
      "loss: 0.020496  [   64/ 4800]\n",
      "Correct: 4781 / 4800 \n",
      "Accuracy: 99.6%, Avg loss: 0.015773 \n",
      "\n",
      "TESTING\n",
      "Correct: 1187.0 / 1200 \n",
      "Accuracy: 98.9%, Avg loss: 0.028995 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.9892143607139587\n",
      "Best Epoch F1:  0.9535766839981079\n",
      "Saving new best model...\n",
      "\n",
      "EPOCH 3\n",
      "\n",
      "TRAINING\n",
      "loss: 0.007984  [   64/ 4800]\n",
      "Correct: 4797 / 4800 \n",
      "Accuracy: 99.9%, Avg loss: 0.003790 \n",
      "\n",
      "TESTING\n",
      "Correct: 1195.0 / 1200 \n",
      "Accuracy: 99.6%, Avg loss: 0.007108 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.995838463306427\n",
      "Best Epoch F1:  0.9892143607139587\n",
      "Saving new best model...\n",
      "\n",
      "EPOCH 4\n",
      "\n",
      "TRAINING\n",
      "loss: 0.000765  [   64/ 4800]\n",
      "Correct: 4797 / 4800 \n",
      "Accuracy: 99.9%, Avg loss: 0.002656 \n",
      "\n",
      "TESTING\n",
      "Correct: 1198.0 / 1200 \n",
      "Accuracy: 99.8%, Avg loss: 0.008371 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.9983348250389099\n",
      "Best Epoch F1:  0.995838463306427\n",
      "Saving new best model...\n",
      "\n",
      "EPOCH 5\n",
      "\n",
      "TRAINING\n",
      "loss: 0.000286  [   64/ 4800]\n",
      "Correct: 4796 / 4800 \n",
      "Accuracy: 99.9%, Avg loss: 0.003104 \n",
      "\n",
      "TESTING\n",
      "Correct: 1198.0 / 1200 \n",
      "Accuracy: 99.8%, Avg loss: 0.004170 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.9983334541320801\n",
      "Best Epoch F1:  0.9983348250389099\n",
      "\n",
      "Best Epoch:  4  \n",
      " Best F1 Score:  0.9983348250389099\n",
      "\n",
      "EPOCH 1\n",
      "\n",
      "TRAINING\n",
      "loss: 1.815728  [   64/ 4800]\n",
      "Correct: 4468 / 4800 \n",
      "Accuracy: 93.1%, Avg loss: 0.361124 \n",
      "\n",
      "TESTING\n",
      "Correct: 1189.0 / 1200 \n",
      "Accuracy: 99.1%, Avg loss: 0.049615 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.9908706545829773\n",
      "Best Epoch F1:  0\n",
      "Saving new best model...\n",
      "\n",
      "EPOCH 2\n",
      "\n",
      "TRAINING\n",
      "loss: 0.003935  [   64/ 4800]\n",
      "Correct: 4778 / 4800 \n",
      "Accuracy: 99.5%, Avg loss: 0.014348 \n",
      "\n",
      "TESTING\n",
      "Correct: 1194.0 / 1200 \n",
      "Accuracy: 99.5%, Avg loss: 0.020136 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.9950001239776611\n",
      "Best Epoch F1:  0.9908706545829773\n",
      "Saving new best model...\n",
      "\n",
      "EPOCH 3\n",
      "\n",
      "TRAINING\n",
      "loss: 0.003288  [   64/ 4800]\n",
      "Correct: 4786 / 4800 \n",
      "Accuracy: 99.7%, Avg loss: 0.009954 \n",
      "\n",
      "TESTING\n",
      "Correct: 1189.0 / 1200 \n",
      "Accuracy: 99.1%, Avg loss: 0.024738 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.9908885359764099\n",
      "Best Epoch F1:  0.9950001239776611\n",
      "\n",
      "EPOCH 4\n",
      "\n",
      "TRAINING\n",
      "loss: 0.004469  [   64/ 4800]\n",
      "Correct: 4797 / 4800 \n",
      "Accuracy: 99.9%, Avg loss: 0.003713 \n",
      "\n",
      "TESTING\n",
      "Correct: 1197.0 / 1200 \n",
      "Accuracy: 99.8%, Avg loss: 0.006477 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.9974998831748962\n",
      "Best Epoch F1:  0.9950001239776611\n",
      "Saving new best model...\n",
      "\n",
      "EPOCH 5\n",
      "\n",
      "TRAINING\n",
      "loss: 0.000363  [   64/ 4800]\n",
      "Correct: 4800 / 4800 \n",
      "Accuracy: 100.0%, Avg loss: 0.001185 \n",
      "\n",
      "TESTING\n",
      "Correct: 1196.0 / 1200 \n",
      "Accuracy: 99.7%, Avg loss: 0.011044 \n",
      "\n",
      "FINISHING EPOCH\n",
      "Current Epoch F1:  0.9966716170310974\n",
      "Best Epoch F1:  0.9974998831748962\n",
      "\n",
      "Best Epoch:  4  \n",
      " Best F1 Score:  0.9974998831748962\n"
     ]
    }
   ],
   "source": [
    "rm = RunManager(number_of_classes)\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    " \n",
    "    #define project and run names \n",
    "    run_name = f'{dataset_version}-{run.model}_{run.trainset}_b{run.batch_size}_lr{run.lr}_e{run.epochs}'\n",
    "\n",
    "    #setup all the WandB variables\n",
    "    # wandb.init(\n",
    "    #     project=project_name,\n",
    "    #     config={\n",
    "    #         \"learning_rate\": run.lr,\n",
    "    #         \"batch_size\": run.batch_size,\n",
    "    #         \"architecture\": run.model,\n",
    "    #         \"dataset\": run.trainset,\n",
    "    #         \"epochs\": run.epochs,\n",
    "    #         \"run_name\" : custom_run_name\n",
    "    #     }) \n",
    "    # wandb.run.name = custom_run_name\n",
    "\n",
    "    #passing batch of images to model\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        trainsets[run.trainset]['train'], \n",
    "        batch_size=run.batch_size, \n",
    "        shuffle=run.shuffle, \n",
    "        num_workers = run.num_workers,\n",
    "    )\n",
    "\n",
    "    #this is used at the end of every epoch to give a score each epoch\n",
    "    validation_loader = torch.utils.data.DataLoader(\n",
    "        trainsets[run.trainset]['test'],\n",
    "        batch_size=run.batch_size, \n",
    "        num_workers = run.num_workers\n",
    "    )\n",
    "\n",
    "    #load a model from the model factory\n",
    "    model = ModelFactory.get_network(run.model, number_of_classes).to(device)\n",
    "\n",
    "    #define loss function and optimizer\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=run.lr)\n",
    "\n",
    "    #variables to keep track of the best performing epoch (based on F1)\n",
    "    best_epoch_F1 = 0\n",
    "    best_epoch = 1\n",
    "\n",
    "    #initialilse the run in the RunManager\n",
    "    rm.begin_run(run, model, loader, device, run_name)\n",
    "    \n",
    "\n",
    "    for epoch in range(run.epochs):\n",
    "        \n",
    "        #initialilse the current epoch in the RunManager\n",
    "        rm.begin_epoch()\n",
    "        \n",
    "        print(f'\\nEPOCH {epoch+1}')\n",
    "        print(\"\\nTRAINING\")\n",
    "\n",
    "        #variables to track loss and correct predictions over the epoch\n",
    "        running_loss = 0\n",
    "        correct = 0\n",
    "        \n",
    "        #get total number of images in dataset\n",
    "        size = len(loader.dataset)\n",
    "\n",
    "        #set the model to train mode\n",
    "        model.train()\n",
    "\n",
    "        \n",
    "        for batch, (images,labels) in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            if run.model == 'inception_v3':\n",
    "                preds, x = model(images) #pass batch\n",
    "            else:\n",
    "                preds = model(images)\n",
    "\n",
    "            loss = loss_fn(preds, labels) # calculate loss\n",
    "\n",
    "            \n",
    "            correct += preds.argmax(dim=1).eq(labels).sum().item()\n",
    "            \n",
    "            loss.backward() # calculate gradients\n",
    "            optimizer.step() # update weights\n",
    "            optimizer.zero_grad() # zero out gradients\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                f_loss, current = loss.item(), (batch + 1) * len(images)\n",
    "                print(f\"loss: {f_loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "            running_loss += loss.item()\n",
    "                \n",
    "        \n",
    "        running_loss /= len(loader)\n",
    "        accuracy = correct / len(loader.dataset)\n",
    "\n",
    "        print(f\"Correct: {correct} / {len(loader.dataset)} \")        \n",
    "        print(f\"Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {running_loss:>8f} \\n\")\n",
    "        \n",
    "\n",
    "        rm.epoch_loss = running_loss\n",
    "        rm.epoch_accuracy = accuracy\n",
    "\n",
    "        print(\"TESTING\")\n",
    "\n",
    "        test_loss = 0\n",
    "        test_correct = 0\n",
    "\n",
    "        test_size = len(validation_loader.dataset)\n",
    "        num_batches = len(validation_loader)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for test_images, test_labels in validation_loader:\n",
    "\n",
    "                test_images = test_images.to(device)\n",
    "                test_labels = test_labels.to(device)\n",
    "                  \n",
    "                test_preds = model(test_images)\n",
    "                test_loss += loss_fn(test_preds, test_labels).item() # calculate loss\n",
    "                test_correct += (test_preds.argmax(1) == test_labels).type(torch.float).sum().item()\n",
    "                \n",
    "                rm.update_metrics(test_preds, test_labels)\n",
    "        \n",
    "        test_loss /= len(validation_loader)\n",
    "        test_accuracy = test_correct / len(validation_loader.dataset)  \n",
    "        \n",
    "        print(f\"Correct: {test_correct} / {len(validation_loader.dataset)} \")      \n",
    "        print(f\"Accuracy: {(100*test_accuracy):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "                    \n",
    "        #pass test loss and accuracy to the run manager \n",
    "        rm.epoch_test_loss = test_loss\n",
    "        rm.epoch_test_accuracy =  test_accuracy\n",
    "        rm.calculate_metrics()\n",
    "\n",
    "        print(\"FINISHING EPOCH\")\n",
    "        print(\"Current Epoch F1: \", rm.epoch_weighted_F1)\n",
    "        print(\"Best Epoch F1: \", best_epoch_F1)\n",
    "        \n",
    "        #only save the best models according to F1 score\n",
    "        if rm.epoch_weighted_F1 > best_epoch_F1:\n",
    "            print(\"Saving new best model...\")\n",
    "            torch.save(model.state_dict(), 'models/BEST_' + run_name + '_' + str(epoch+1) ) \n",
    "            best_epoch_F1 = rm.epoch_weighted_F1 \n",
    "            best_epoch = epoch+1\n",
    "\n",
    "        #log key metrics to weights and biases\n",
    "        # wandb.log({\"acc\": accuracy, \"loss\": loss, \"val_precision\": rm.epoch_precision, \"val_recall\": rm.epoch_recall,\n",
    "        #             \"val_acc\": rm.epoch_test_accuracy,\"val_loss\": test_loss, \"F1 Score\": rm.epoch_F1,\n",
    "        #             \"F1 weighted Score\": rm.epoch_weighted_F1, \"auprc\": rm.epoch_auprc, \"auroc\": rm.epoch_auroc })\n",
    "        \n",
    "        rm.end_epoch()\n",
    "    print(\"\\nBest Epoch: \" , best_epoch , \" \\n Best F1 Score: \" , best_epoch_F1)\n",
    "    torch.cuda.empty_cache()\n",
    "    rm.save(run_name)\n",
    "    #wandb.finish()\n",
    "rm.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
